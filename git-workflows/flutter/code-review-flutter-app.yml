name: Flutter Code Review - Claude AI

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'lib/**/*.dart'
      - 'test/**/*.dart'
      - 'pubspec.yaml'
      - 'analysis_options.yaml'

# Prevent multiple runs for the same PR
concurrency:
  group: code-review-${{ github.event.pull_request.number }}
  cancel-in-progress: true

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  code-review:
    name: AI Code Review
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for better diff

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: '3.24.0'
          channel: 'stable'
          cache: true

      - name: Flutter Doctor
        run: flutter doctor -v

      - name: Install Dependencies
        run: flutter pub get

      - name: Get PR information
        id: pr-info
        env:
          GH_TOKEN: ${{ secrets.VOLTOP_GITHUB_PAT }}
        run: |
          PR_NUMBER="${{ github.event.pull_request.number }}"
          PR_TITLE="${{ github.event.pull_request.title }}"
          PR_AUTHOR="${{ github.event.pull_request.user.login }}"
          BASE_REF="${{ github.event.pull_request.base.ref }}"
          HEAD_REF="${{ github.event.pull_request.head.ref }}"

          echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
          echo "pr_title=$PR_TITLE" >> $GITHUB_OUTPUT
          echo "pr_author=$PR_AUTHOR" >> $GITHUB_OUTPUT
          echo "base_ref=$BASE_REF" >> $GITHUB_OUTPUT
          echo "head_ref=$HEAD_REF" >> $GITHUB_OUTPUT

          # Save PR body to file (handle multiline and special characters safely)
          cat > pr_body.txt <<'EOF'
          ${{ github.event.pull_request.body }}
          EOF

      - name: Get previous reviews
        id: previous-reviews
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Buscar comentarios anteriores del bot en este PR
          gh api repos/${{ github.repository }}/issues/${{ steps.pr-info.outputs.pr_number }}/comments \
            --jq '.[] | select(.user.login == "github-actions[bot]") | select(.body | contains("ðŸ¤– AI Code Review"))' \
            > previous_reviews.json

          # Contar reviews anteriores
          REVIEW_COUNT=$(jq -s 'length' previous_reviews.json)
          echo "count=$REVIEW_COUNT" >> $GITHUB_OUTPUT
          echo "ðŸ“Š Found $REVIEW_COUNT previous review(s)"

          # Si hay reviews anteriores, extraer la Ãºltima
          if [ "$REVIEW_COUNT" -gt 0 ]; then
            echo "Processing last review..."

            # Extraer la Ãºltima review
            jq -s '.[-1]' previous_reviews.json > last_review.json

            # Extraer fecha de la Ãºltima review
            LAST_REVIEW_DATE=$(jq -r '.created_at' last_review.json)
            echo "last_review_date=$LAST_REVIEW_DATE" >> $GITHUB_OUTPUT

            # Extraer mÃ©tricas anteriores del body del comentario
            REVIEW_BODY=$(jq -r '.body' last_review.json)

            # Buscar scores en el formato "Architecture Score**: X/10"
            LAST_ARCH=$(echo "$REVIEW_BODY" | grep -oP 'Architecture Score\*\*:\s*\K\d+(?=/10)' | head -1 || echo "N/A")
            LAST_QUALITY=$(echo "$REVIEW_BODY" | grep -oP 'Code Quality Score\*\*:\s*\K\d+(?=/10)' | head -1 || echo "N/A")
            LAST_TEST=$(echo "$REVIEW_BODY" | grep -oP 'Testing Score\*\*:\s*\K\d+(?=/10)' | head -1 || echo "N/A")

            # TambiÃ©n buscar en el formato alternativo "Architecture (Score: X/10)"
            if [ "$LAST_ARCH" = "N/A" ]; then
              LAST_ARCH=$(echo "$REVIEW_BODY" | grep -oP 'Architecture.*?[Ss]core.*?:\s*\K\d+(?=/10)' | head -1 || echo "N/A")
            fi
            if [ "$LAST_QUALITY" = "N/A" ]; then
              LAST_QUALITY=$(echo "$REVIEW_BODY" | grep -oP 'Code Quality.*?[Ss]core.*?:\s*\K\d+(?=/10)' | head -1 || echo "N/A")
            fi
            if [ "$LAST_TEST" = "N/A" ]; then
              LAST_TEST=$(echo "$REVIEW_BODY" | grep -oP 'Testing.*?[Ss]core.*?:\s*\K\d+(?=/10)' | head -1 || echo "N/A")
            fi

            echo "last_arch=$LAST_ARCH" >> $GITHUB_OUTPUT
            echo "last_quality=$LAST_QUALITY" >> $GITHUB_OUTPUT
            echo "last_test=$LAST_TEST" >> $GITHUB_OUTPUT

            echo "ðŸ“ˆ Previous metrics: Arch=$LAST_ARCH, Quality=$LAST_QUALITY, Testing=$LAST_TEST"

            # Guardar el body completo para incluirlo en el contexto
            echo "$REVIEW_BODY" > last_review_body.txt

            # Extraer action items si existen
            echo "$REVIEW_BODY" | sed -n '/Action Items/,/^---$/p' > previous_action_items.txt || true
          else
            echo "This is the first review for this PR"
            echo "last_arch=N/A" >> $GITHUB_OUTPUT
            echo "last_quality=N/A" >> $GITHUB_OUTPUT
            echo "last_test=N/A" >> $GITHUB_OUTPUT
          fi

      - name: Run Flutter Analyze
        id: flutter-analyze
        continue-on-error: true
        run: |
          flutter analyze > analyze_output.txt 2>&1 || true
          cat analyze_output.txt

          # Count issues
          ISSUE_COUNT=$(grep -c "error â€¢\|warning â€¢\|info â€¢" analyze_output.txt || echo "0")
          echo "issue_count=$ISSUE_COUNT" >> $GITHUB_OUTPUT

      - name: Get changed files
        id: changed-files
        run: |
          # Get list of changed Dart files
          git diff --name-only origin/${{ steps.pr-info.outputs.base_ref }}...HEAD \
            | grep '\.dart$' \
            | tee changed_files.txt

          CHANGED_COUNT=$(wc -l < changed_files.txt || echo "0")
          echo "count=$CHANGED_COUNT" >> $GITHUB_OUTPUT

          # Get lines changed
          LINES_ADDED=$(git diff --numstat origin/${{ steps.pr-info.outputs.base_ref }}...HEAD | awk '{sum+=$1} END {print sum}' || echo "0")
          LINES_DELETED=$(git diff --numstat origin/${{ steps.pr-info.outputs.base_ref }}...HEAD | awk '{sum+=$2} END {print sum}' || echo "0")

          echo "lines_added=$LINES_ADDED" >> $GITHUB_OUTPUT
          echo "lines_deleted=$LINES_DELETED" >> $GITHUB_OUTPUT

      - name: Get file diffs
        id: file-diffs
        run: |
          # Create diffs for changed files
          mkdir -p diffs

          while IFS= read -r file; do
            if [ -f "$file" ]; then
              echo "=== DIFF FOR: $file ===" >> diffs/all_diffs.txt
              git diff origin/${{ steps.pr-info.outputs.base_ref }}...HEAD -- "$file" >> diffs/all_diffs.txt
              echo "" >> diffs/all_diffs.txt
            fi
          done < changed_files.txt

          # Limit diff size (Claude has token limits)
          DIFF_SIZE=$(wc -c < diffs/all_diffs.txt)
          MAX_SIZE=150000  # ~50K tokens

          if [ $DIFF_SIZE -gt $MAX_SIZE ]; then
            echo "âš ï¸ Diff too large ($DIFF_SIZE bytes), truncating..."
            head -c $MAX_SIZE diffs/all_diffs.txt > diffs/all_diffs_truncated.txt
            echo "\n\n[... Diff truncated due to size ...]" >> diffs/all_diffs_truncated.txt
            mv diffs/all_diffs_truncated.txt diffs/all_diffs.txt
          fi

          echo "diff_size=$DIFF_SIZE" >> $GITHUB_OUTPUT

      - name: Prepare review context
        id: context
        run: |
          cat > review_context.json <<EOF
          {
            "pr_number": "${{ steps.pr-info.outputs.pr_number }}",
            "pr_title": "${{ steps.pr-info.outputs.pr_title }}",
            "pr_author": "${{ steps.pr-info.outputs.pr_author }}",
            "base_branch": "${{ steps.pr-info.outputs.base_ref }}",
            "head_branch": "${{ steps.pr-info.outputs.head_ref }}",
            "files_changed": ${{ steps.changed-files.outputs.count }},
            "lines_added": ${{ steps.changed-files.outputs.lines_added }},
            "lines_deleted": ${{ steps.changed-files.outputs.lines_deleted }},
            "repository": "${{ github.repository }}"
          }
          EOF

      - name: Call Claude API for Review
        id: claude-review
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # Build the user prompt
          REVIEW_COUNT=${{ steps.previous-reviews.outputs.count }}
          REVIEW_NUMBER=$((REVIEW_COUNT + 1))

          echo "Please review this Pull Request:" > user_prompt.txt
          echo "" >> user_prompt.txt
          echo "## PR Information" >> user_prompt.txt
          cat review_context.json >> user_prompt.txt
          echo "" >> user_prompt.txt

          # Include previous review context if exists
          if [ "$REVIEW_COUNT" -gt 0 ]; then
            echo "## ðŸ“Š Previous Review Context" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "**This is an INCREMENTAL REVIEW** - Review #$REVIEW_NUMBER" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "### Previous Review Summary" >> user_prompt.txt
            echo "- **Review Date**: ${{ steps.previous-reviews.outputs.last_review_date }}" >> user_prompt.txt
            echo "- **Previous Metrics**:" >> user_prompt.txt
            echo "  - Architecture: ${{ steps.previous-reviews.outputs.last_arch }}/10" >> user_prompt.txt
            echo "  - Code Quality: ${{ steps.previous-reviews.outputs.last_quality }}/10" >> user_prompt.txt
            echo "  - Testing: ${{ steps.previous-reviews.outputs.last_test }}/10" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "### Previous Review Feedback" >> user_prompt.txt
            echo "" >> user_prompt.txt

            # Include relevant sections from previous review
            if [ -f last_review_body.txt ]; then
              # Extract Action Items section if it exists
              if grep -q "Action Items" last_review_body.txt; then
                echo "**Previous Action Items:**" >> user_prompt.txt
                sed -n '/Action Items/,/^---$/p' last_review_body.txt | head -50 >> user_prompt.txt
                echo "" >> user_prompt.txt
              fi

              # Extract key issues from previous review (limit to avoid token overflow)
              echo "**Key Points from Previous Review:**" >> user_prompt.txt
              echo '```' >> user_prompt.txt
              # Get sections with issues (limited to 100 lines)
              grep -A 3 "âŒ\|âš ï¸\|Issues Found\|Must Fix" last_review_body.txt | head -100 >> user_prompt.txt || echo "No critical issues in previous review" >> user_prompt.txt
              echo '```' >> user_prompt.txt
              echo "" >> user_prompt.txt
            fi

            echo "---" >> user_prompt.txt
            echo "" >> user_prompt.txt
          fi

          echo "## PR Description" >> user_prompt.txt
          cat pr_body.txt >> user_prompt.txt
          echo "" >> user_prompt.txt
          echo "## Flutter Analyze Results" >> user_prompt.txt
          echo "Issues found: ${{ steps.flutter-analyze.outputs.issue_count }}" >> user_prompt.txt
          echo '```' >> user_prompt.txt
          cat analyze_output.txt >> user_prompt.txt
          echo '```' >> user_prompt.txt
          echo "" >> user_prompt.txt
          echo "## Changed Files" >> user_prompt.txt
          cat changed_files.txt >> user_prompt.txt
          echo "" >> user_prompt.txt
          echo "## File Diffs" >> user_prompt.txt
          echo '```diff' >> user_prompt.txt
          cat diffs/all_diffs.txt >> user_prompt.txt
          echo '```' >> user_prompt.txt
          echo "" >> user_prompt.txt

          # Add instructions based on review type
          if [ "$REVIEW_COUNT" -gt 0 ]; then
            echo "## âš ï¸ CRITICAL INSTRUCTIONS FOR INCREMENTAL REVIEW" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "**THIS IS REVIEW #$REVIEW_NUMBER** - The PR has been reviewed $REVIEW_COUNT time(s) before." >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "You MUST follow this process:" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "1. **Compare with Previous Review**:" >> user_prompt.txt
            echo "   - Review the previous feedback and action items above" >> user_prompt.txt
            echo "   - Identify which issues were addressed in the current changes" >> user_prompt.txt
            echo "   - Note which issues remain unaddressed" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "2. **Validate Progress**:" >> user_prompt.txt
            echo "   - Mark previous action items as COMPLETED âœ… if properly fixed" >> user_prompt.txt
            echo "   - Mark as PARTIALLY COMPLETED âš ï¸ if partially addressed" >> user_prompt.txt
            echo "   - Mark as NOT ADDRESSED âŒ if still pending" >> user_prompt.txt
            echo "   - Identify any NEW ISSUES ðŸ†• not mentioned before" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "3. **Update Metrics Based on Progress**:" >> user_prompt.txt
            echo "   - **INCREASE** metrics if critical issues were fixed" >> user_prompt.txt
            echo "   - **DECREASE** metrics if new critical issues appeared or quality regressed" >> user_prompt.txt
            echo "   - **MAINTAIN** metrics if no significant change" >> user_prompt.txt
            echo "   - Previous: Arch=${{ steps.previous-reviews.outputs.last_arch }}, Quality=${{ steps.previous-reviews.outputs.last_quality }}, Testing=${{ steps.previous-reviews.outputs.last_test }}" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "4. **Structure Your Review**:" >> user_prompt.txt
            echo "   - Start with a \"Progress Since Last Review\" section" >> user_prompt.txt
            echo "   - Show metric evolution with arrows (â†‘ increased, â†“ decreased, â†’ unchanged)" >> user_prompt.txt
            echo "   - Explain WHY each metric changed or stayed the same" >> user_prompt.txt
            echo "   - Only mention NEW issues or PERSISTENT unresolved issues" >> user_prompt.txt
            echo "   - Acknowledge and recognize improvements made" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "5. **Decision Logic**:" >> user_prompt.txt
            echo "   - APPROVE if all previous critical issues are fixed AND no new critical issues" >> user_prompt.txt
            echo "   - REQUEST_CHANGES if previous critical issues remain OR new critical issues found" >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "**IMPORTANT**: Do NOT re-report issues that were already fixed. Recognize the developer's effort." >> user_prompt.txt
            echo "" >> user_prompt.txt
            echo "---" >> user_prompt.txt
            echo "" >> user_prompt.txt
          fi

          echo "Provide a comprehensive code review following your review process. Include:" >> user_prompt.txt
          echo "1. Overall assessment (APPROVE/REQUEST_CHANGES)" >> user_prompt.txt
          echo "2. Architecture analysis" >> user_prompt.txt
          echo "3. Code quality issues" >> user_prompt.txt
          echo "4. Testing coverage" >> user_prompt.txt
          echo "5. Security concerns" >> user_prompt.txt
          echo "6. Specific actionable recommendations" >> user_prompt.txt
          echo "" >> user_prompt.txt
          echo "Format your response in Markdown." >> user_prompt.txt

          # Create API request using jq for proper JSON escaping
          # Using reviewer-flutter-app agent since this is a library project
          jq -n \
            --rawfile system .claude/agents/reviewer-flutter-app.md \
            --rawfile prompt user_prompt.txt \
            '{
              "model": "claude-sonnet-4-20250514",
              "max_tokens": 4096,
              "system": $system,
              "messages": [
                {
                  "role": "user",
                  "content": $prompt
                }
              ]
            }' > api_request.json

          # Call Claude API
          RESPONSE=$(curl -s -X POST https://api.anthropic.com/v1/messages \
            -H "x-api-key: $ANTHROPIC_API_KEY" \
            -H "anthropic-version: 2023-06-01" \
            -H "content-type: application/json" \
            -d @api_request.json)

          # Extract review content
          REVIEW_CONTENT=$(echo "$RESPONSE" | jq -r '.content[0].text')

          # Save review to file
          echo "$REVIEW_CONTENT" > claude_review.md

          # Determine review decision
          if echo "$REVIEW_CONTENT" | grep -q "APPROVE"; then
            DECISION="APPROVE"
          elif echo "$REVIEW_CONTENT" | grep -q "REQUEST_CHANGES\|REQUEST CHANGES"; then
            DECISION="REQUEST_CHANGES"
          else
            DECISION="COMMENT"
          fi

          echo "decision=$DECISION" >> $GITHUB_OUTPUT

          # Extract scores if present (Flutter-specific categories)
          ARCH_SCORE=$(echo "$REVIEW_CONTENT" | grep -oP "Architecture.*?\|\s*\K\d+(?=/10)" | head -1 || echo "N/A")
          PATTERN_SCORE=$(echo "$REVIEW_CONTENT" | grep -oP "Pattern Consistency.*?\|\s*\K\d+(?=/10)" | head -1 || echo "N/A")
          QUALITY_SCORE=$(echo "$REVIEW_CONTENT" | grep -oP "Code Quality.*?\|\s*\K\d+(?=/10)" | head -1 || echo "N/A")
          TEST_SCORE=$(echo "$REVIEW_CONTENT" | grep -oP "Testing Coverage.*?\|\s*\K\d+(?=/10)" | head -1 || echo "N/A")
          SECURITY_SCORE=$(echo "$REVIEW_CONTENT" | grep -oP "Security.*?\|\s*\K\d+(?=/10)" | head -1 || echo "N/A")

          echo "arch_score=$ARCH_SCORE" >> $GITHUB_OUTPUT
          echo "pattern_score=$PATTERN_SCORE" >> $GITHUB_OUTPUT
          echo "quality_score=$QUALITY_SCORE" >> $GITHUB_OUTPUT
          echo "test_score=$TEST_SCORE" >> $GITHUB_OUTPUT
          echo "security_score=$SECURITY_SCORE" >> $GITHUB_OUTPUT

      - name: Post Review Comment
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Read review content
          REVIEW_BODY=$(cat claude_review.md)

          # Calculate review number
          REVIEW_COUNT=${{ steps.previous-reviews.outputs.count }}
          REVIEW_NUMBER=$((REVIEW_COUNT + 1))

          # Get current and previous metrics
          CURRENT_ARCH="${{ steps.claude-review.outputs.arch_score }}"
          CURRENT_PATTERN="${{ steps.claude-review.outputs.pattern_score }}"
          CURRENT_QUALITY="${{ steps.claude-review.outputs.quality_score }}"
          CURRENT_TEST="${{ steps.claude-review.outputs.test_score }}"
          CURRENT_SECURITY="${{ steps.claude-review.outputs.security_score }}"

          PREV_ARCH="${{ steps.previous-reviews.outputs.last_arch }}"
          PREV_QUALITY="${{ steps.previous-reviews.outputs.last_quality }}"
          PREV_TEST="${{ steps.previous-reviews.outputs.last_test }}"

          # Function to calculate change indicator
          get_change_indicator() {
            current=$1
            previous=$2

            if [ "$previous" = "N/A" ] || [ "$current" = "N/A" ]; then
              echo ""
              return
            fi

            if [ "$current" -gt "$previous" ]; then
              echo " â†‘ (+$((current - previous)))"
            elif [ "$current" -lt "$previous" ]; then
              echo " â†“ (-$((previous - current)))"
            else
              echo " â†’"
            fi
          }

          # Calculate change indicators
          ARCH_CHANGE=$(get_change_indicator "$CURRENT_ARCH" "$PREV_ARCH")
          PATTERN_CHANGE=$(get_change_indicator "$CURRENT_PATTERN" "N/A")
          QUALITY_CHANGE=$(get_change_indicator "$CURRENT_QUALITY" "$PREV_QUALITY")
          TEST_CHANGE=$(get_change_indicator "$CURRENT_TEST" "$PREV_TEST")
          SECURITY_CHANGE=$(get_change_indicator "$CURRENT_SECURITY" "N/A")

          # Build metrics section
          if [ "$REVIEW_COUNT" -gt 0 ]; then
            METRICS_SECTION="<details>
          <summary>ðŸ“Š Review Metrics (Review #$REVIEW_NUMBER)</summary>

          ### Current Scores
          - **Architecture**: $CURRENT_ARCH/10$ARCH_CHANGE
          - **Pattern Consistency**: $CURRENT_PATTERN/10$PATTERN_CHANGE
          - **Code Quality**: $CURRENT_QUALITY/10$QUALITY_CHANGE
          - **Testing Coverage**: $CURRENT_TEST/10$TEST_CHANGE
          - **Security**: $CURRENT_SECURITY/10$SECURITY_CHANGE

          ### Previous Scores (Review #$REVIEW_COUNT)
          - Architecture: $PREV_ARCH/10
          - Code Quality: $PREV_QUALITY/10
          - Testing: $PREV_TEST/10

          ### Evolution
          $(if [ -n "$ARCH_CHANGE" ]; then echo "- Architecture: $PREV_ARCH â†’ $CURRENT_ARCH$ARCH_CHANGE"; fi)
          $(if [ -n "$QUALITY_CHANGE" ]; then echo "- Code Quality: $PREV_QUALITY â†’ $CURRENT_QUALITY$QUALITY_CHANGE"; fi)
          $(if [ -n "$TEST_CHANGE" ]; then echo "- Testing: $PREV_TEST â†’ $CURRENT_TEST$TEST_CHANGE"; fi)

          **Decision**: \`${{ steps.claude-review.outputs.decision }}\`

          </details>"
          else
            METRICS_SECTION="<details>
          <summary>ðŸ“Š Review Metrics (Initial Review)</summary>

          - **Architecture**: $CURRENT_ARCH/10
          - **Pattern Consistency**: $CURRENT_PATTERN/10
          - **Code Quality**: $CURRENT_QUALITY/10
          - **Testing Coverage**: $CURRENT_TEST/10
          - **Security**: $CURRENT_SECURITY/10
          - **Decision**: \`${{ steps.claude-review.outputs.decision }}\`

          </details>"
          fi

          # Add metadata header
          REVIEW_WITH_HEADER="## ðŸ¤– AI Code Review by Claude $(if [ "$REVIEW_COUNT" -gt 0 ]; then echo "(Review #$REVIEW_NUMBER)"; fi)

          **Reviewer**: Claude Sonnet 4.5
          **Review Date**: $(date -u +'%Y-%m-%d %H:%M:%S UTC')
          **Files Analyzed**: ${{ steps.changed-files.outputs.count }}
          **Lines Changed**: +${{ steps.changed-files.outputs.lines_added }} / -${{ steps.changed-files.outputs.lines_deleted }}
          $(if [ "$REVIEW_COUNT" -gt 0 ]; then echo "**Previous Review**: ${{ steps.previous-reviews.outputs.last_review_date }}"; fi)

          ---

          $REVIEW_BODY

          ---

          $METRICS_SECTION

          ---

          *This review was generated automatically by Claude AI. Please use your judgment when addressing feedback.*"

          # Post as issue comment (not PR review) to enable history tracking
          gh issue comment ${{ steps.pr-info.outputs.pr_number }} \
            --body "$REVIEW_WITH_HEADER"

      - name: Create Check Run
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          DECISION="${{ steps.claude-review.outputs.decision }}"

          if [ "$DECISION" = "APPROVE" ]; then
            CONCLUSION="success"
            TITLE="âœ… Code Review Passed"
            SUMMARY="Claude AI approved this PR. All quality criteria met."
          elif [ "$DECISION" = "REQUEST_CHANGES" ]; then
            CONCLUSION="failure"
            TITLE="âŒ Code Review: Changes Requested"
            SUMMARY="Claude AI identified issues that need to be addressed before merge."
          else
            CONCLUSION="neutral"
            TITLE="ðŸ’¬ Code Review: Comments"
            SUMMARY="Claude AI provided feedback for consideration."
          fi

          # Create check via API
          curl -X POST \
            -H "Authorization: token $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/${{ github.repository }}/check-runs \
            -d "{
              \"name\": \"Claude Code Review\",
              \"head_sha\": \"${{ github.event.pull_request.head.sha }}\",
              \"status\": \"completed\",
              \"conclusion\": \"$CONCLUSION\",
              \"output\": {
                \"title\": \"$TITLE\",
                \"summary\": \"$SUMMARY\",
                \"text\": \"See PR comments for detailed review.\"
              }
            }"

      - name: Generate Review Summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY <<EOF
          # ðŸ¤– Claude Code Review Summary

          ## PR Information
          - **PR #**: ${{ steps.pr-info.outputs.pr_number }}
          - **Title**: ${{ steps.pr-info.outputs.pr_title }}
          - **Author**: @${{ steps.pr-info.outputs.pr_author }}

          ## Changes
          - **Files Changed**: ${{ steps.changed-files.outputs.count }}
          - **Lines Added**: ${{ steps.changed-files.outputs.lines_added }}
          - **Lines Deleted**: ${{ steps.changed-files.outputs.lines_deleted }}

          ## Review Scores
          - ðŸ—ï¸ **Architecture**: ${{ steps.claude-review.outputs.arch_score }}/10
          - ðŸŽ¨ **Pattern Consistency**: ${{ steps.claude-review.outputs.pattern_score }}/10
          - ðŸ’» **Code Quality**: ${{ steps.claude-review.outputs.quality_score }}/10
          - ðŸ§ª **Testing Coverage**: ${{ steps.claude-review.outputs.test_score }}/10
          - ðŸ”’ **Security**: ${{ steps.claude-review.outputs.security_score }}/10
          - ðŸ“Š **Flutter Analyze Issues**: ${{ steps.flutter-analyze.outputs.issue_count }}

          ## Decision
          **${{ steps.claude-review.outputs.decision }}**

          ---

          See PR comments for detailed feedback.
          EOF

      - name: Upload Review Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: code-review-${{ steps.pr-info.outputs.pr_number }}
          path: |
            claude_review.md
            review_context.json
            changed_files.txt
            diffs/
          retention-days: 30

      - name: Block Merge if Quality Standards Not Met
        if: always()
        run: |
          # Get metrics
          ARCH_SCORE="${{ steps.claude-review.outputs.arch_score }}"
          PATTERN_SCORE="${{ steps.claude-review.outputs.pattern_score }}"
          QUALITY_SCORE="${{ steps.claude-review.outputs.quality_score }}"
          TEST_SCORE="${{ steps.claude-review.outputs.test_score }}"
          SECURITY_SCORE="${{ steps.claude-review.outputs.security_score }}"
          DECISION="${{ steps.claude-review.outputs.decision }}"

          # Quality thresholds (Flutter-specific policy)
          REQUIRED_ARCH=8
          REQUIRED_PATTERN=8
          REQUIRED_QUALITY=7
          REQUIRED_TEST=7
          REQUIRED_SECURITY=8

          BLOCKING_ISSUES=()

          # Check metrics only (ignore textual decision for consistency)
          # Metrics are more objective than APPROVE/REQUEST_CHANGES decision
          if [ "$ARCH_SCORE" != "N/A" ] && [ "$ARCH_SCORE" -lt "$REQUIRED_ARCH" ]; then
            BLOCKING_ISSUES+=("Architecture: $ARCH_SCORE/10 (required: >= $REQUIRED_ARCH/10)")
          fi

          if [ "$PATTERN_SCORE" != "N/A" ] && [ "$PATTERN_SCORE" -lt "$REQUIRED_PATTERN" ]; then
            BLOCKING_ISSUES+=("Pattern Consistency: $PATTERN_SCORE/10 (required: >= $REQUIRED_PATTERN/10)")
          fi

          if [ "$QUALITY_SCORE" != "N/A" ] && [ "$QUALITY_SCORE" -lt "$REQUIRED_QUALITY" ]; then
            BLOCKING_ISSUES+=("Code Quality: $QUALITY_SCORE/10 (required: >= $REQUIRED_QUALITY/10)")
          fi

          if [ "$TEST_SCORE" != "N/A" ] && [ "$TEST_SCORE" -lt "$REQUIRED_TEST" ]; then
            BLOCKING_ISSUES+=("Testing Coverage: $TEST_SCORE/10 (required: >= $REQUIRED_TEST/10)")
          fi

          if [ "$SECURITY_SCORE" != "N/A" ] && [ "$SECURITY_SCORE" -lt "$REQUIRED_SECURITY" ]; then
            BLOCKING_ISSUES+=("Security: $SECURITY_SCORE/10 (required: >= $REQUIRED_SECURITY/10)")
          fi

          # If any blocking issues, fail the check
          if [ ${#BLOCKING_ISSUES[@]} -gt 0 ]; then
            echo "::error::âŒ PR does not meet quality standards for merge"
            echo ""
            echo "ðŸ“Š Quality Gate: FAILED"
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            echo ""
            echo "Blocking Issues:"
            for issue in "${BLOCKING_ISSUES[@]}"; do
              echo "  âŒ $issue"
            done
            echo ""
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            echo ""
            echo "Current Metrics:"
            echo "  â€¢ Architecture: $ARCH_SCORE/10"
            echo "  â€¢ Pattern Consistency: $PATTERN_SCORE/10"
            echo "  â€¢ Code Quality: $QUALITY_SCORE/10"
            echo "  â€¢ Testing Coverage: $TEST_SCORE/10"
            echo "  â€¢ Security: $SECURITY_SCORE/10"
            echo "  â€¢ Decision: $DECISION"
            echo ""
            echo "Required Metrics (Flutter Quality Policy):"
            echo "  â€¢ Architecture: >= $REQUIRED_ARCH/10"
            echo "  â€¢ Pattern Consistency: >= $REQUIRED_PATTERN/10"
            echo "  â€¢ Code Quality: >= $REQUIRED_QUALITY/10"
            echo "  â€¢ Testing Coverage: >= $REQUIRED_TEST/10"
            echo "  â€¢ Security: >= $REQUIRED_SECURITY/10"
            echo ""
            echo "See the review comment on the PR for detailed feedback."
            exit 1
          fi

          echo "âœ… Quality Gate: PASSED"
          echo "All metrics meet the required thresholds (Flutter Quality Policy)."
          echo ""
          echo "Metrics:"
          echo "  â€¢ Architecture: $ARCH_SCORE/10 âœ“ (required: >= $REQUIRED_ARCH/10)"
          echo "  â€¢ Pattern Consistency: $PATTERN_SCORE/10 âœ“ (required: >= $REQUIRED_PATTERN/10)"
          echo "  â€¢ Code Quality: $QUALITY_SCORE/10 âœ“ (required: >= $REQUIRED_QUALITY/10)"
          echo "  â€¢ Testing Coverage: $TEST_SCORE/10 âœ“ (required: >= $REQUIRED_TEST/10)"
          echo "  â€¢ Security: $SECURITY_SCORE/10 âœ“ (required: >= $REQUIRED_SECURITY/10)"
          echo ""
          echo "Note: Quality gate validates numeric metrics based on Flutter best practices."
          echo "Review decision: $DECISION (informational only)"